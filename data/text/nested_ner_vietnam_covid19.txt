5 2 0 2 r p A 1 2 ] L C . s c [ 1 v 6 1 0 1 2 . 4 0 5 2 : v i X r a Nested Named-Entity Recognition on Vietnamese COVID-19: Dataset and Experiments Ngoc C.Lˆe1∗ , Hai-Chung Nguyen Phung1,2∗ , Thu-Huong Pham Thi1 , Hue Vu1 , Phuong-Thao Nguyen Thi1 , Thu-Thuy Tran1 , Hong-Nhung Le Thi1 , Thuy-Duong Nguyen-Thi3 , Thanh-Huy Nguyen4 1School of Applied Mathematics and Informatics, Hanoi University of Science and Technology 2Financial Deep Mind 3National Economics University 4Faculty of Information Technology, Hanoi Open University lechingoc@yahoo.com, {hchung1997, phamhuong.tb2k, hue.hnue, phuongthao100920, thuytrany17, hongnhungkchy0411, thuyduong2379 }@gmail.com, huynt@hou.edu.vn Abstract losses The COVID-19 pandemic caused great worldwide, efforts are taken place to prevent but many countries have failed. In Vietnam, the trace- ability, localization, and quarantine of people who contact with patients contribute to effective disease prevention. However, this is done by hand, and take a lot of work. In this research, we describe a named-entity recognition (NER) study that as- sists in the prevention of COVID-19 pandemic in Vietnam. We also present our manually annotated COVID-19 dataset with nested named entity recog- nition task for Vietnamese which be deﬁned new entity types using for our system. 1 Introduction Covid-19 has been a major problem of human being for the year 2020 and may be even in next years. As in May, 2021, there were more than 150 millions infected people and more than three million deaths so far. Realizing the danger of the disease, countries have taken steps to prevent its spread. In Vietnam, with measures preventing including quick tracking and isolating patients as well as their close contacts, Vietnam can be considered as one of successful experiences with low number of cases and social activities are still in normal con- ditions. Traceability is done by patient interview about their contacts, as well as their movements and activities. Then re- ports is made and sent to the CDC as medical forms. After that, patients’ information is extracted from these reports to assist in preventing the spread of the disease such as: date of symptom, recent contacts and date, isolation as well as admis- sion dates. Based on these information, it is possible to local- ize epidemic and promptly isolate suspected cases, helping to prevent an outbreak of epidemic. These information also give managers whole picture about the current state. However, processing these data requires a lot of time, extracting nec- essary information by hand may takes hours, this slow-down ∗Equal contribution. follow-up plan. Therefore, we propose an information ex- traction system that automatically recognize relevant named entities presented in medical reports. the most In recent years, with the development of NLP in Viet- nam, there have been many Vietnamese NER datasets, most notable are VLSP 2016 [Nguyen and Vu, 2016] and VLSP 2018 [Nguyen et al., 2019] and or re- cent, PhoNER COVID19 [Truong et al., 2021]. Datasets with named entity types contain key information: in VLSP 2016 and VLSP 2018 have persons (PER), organi- zation (ORG), location (LOC), and other entities (MISC). PHONER COVID19 has the patient code (PATIENT ID), person name (PERSON NAME), age (AGE), gender (GEN- DER), job (OCCUPATION), location (LOCATION), organi- zation (ORGANIZATION), symptoms and disease ( SYMP- TOM & DISEASE), transportation (TRANSPORTATION) and date (DATE). In particular, VLSP 2018 has nested entities (i.e., hierarchically structured entities). There are also many Vietnamese NER datasets being developed to contribute to the development of NLP in Vietnam and we would like to be part of that as well. Our dataset contains COVID-19 related information, ex- tracted from articles compiled from reputable online news sites in Vietnam, online data portal, medical reports and anno- tated similarly to VLSP 2018. We also re-checked manually, removed noise and corrupted data and synthesized almost all cases in Vietnam. Our dataset is annotated with eleven dif- ferent named entity types and has nested entities, related to COVID-19 patients in Vietnam, including 10271 sentences and 11128 entities. We then empirically evaluate strong base- line models on our dataset using BiLSTM and the pre-trained language models PhoBERT [Nguyen and Nguyen, 2020]. In the following sections, we will cover studies related to natural language processing with the subject of COVID-19. Next, section 3 describes our dataset, section 4 we present our experiment and in section 5 we summarize the content presented. 2 Related work The White House and the world’s leading group of re- searchers shared the COVID-19 Open Research Dataset Entity Types Description NAME Name of patient GENDER Gender of patient AGE Age of patient ADDRESS Address of patient HOS DATE Date that patient was admitted to hospital SYM DATE Date that symptoms appear in patient ISO DATE Date that patient is isolated POS DATE Date that patient positive for COVID-19 CON DATE Date that patient contact with anyone CON PERSON Person who contact with patient LOCATION Location where the patient passed Table 1: Entity types description (CORD-19) as a large dataset of academic articles related to COVID-19 [Wang et al., 2020]. Many published studies that used CORD-19, many competitions are held on this dataset that attracted a lot of teams to join and contributed many in- teresting and novel solutions. LitCovid [Chen et al., 2020] is a curated literature hub and updated daily based on articles about COVID-19 on PubMed. Kocaman et al [Kocaman and Talby, 2020] combine pre-trained NER mod- els of PySpark that trained on biomedical and clinical dataset in a pipeline and use it to extract knowledge and information from CORD-19. Tan et al [Kieuvongngam et al., 2020] used BERT and GPT-2 for text summarization task on CORD-19. There are also studies of COVID-19 data from social net- work such as Twitter [Zong et al., 2020], [Banda et al., 2020] or Weibo [Hu et al., 2020]. 3 Dataset It is an honor for us to be a few of scientists trusted by the COVID-19 prevention facility to share important and ex- clusive medical reports for COVID-19 prevention research. These reports include patient’s personal information (sensi- tive parts encrypted), person’s events (places visited, people contacted) over a certain period of time. They come from many different medical facilities, are collected at the COVID- 19 prevention facility for medical team to manually extract necessary information to prevent COVID-19. Since reports have no ﬁxed form, rule-based cannot be used to extract nec- essary information from them. So, we propose a NER sys- tem to extract that information automatically. Since data is still quite small, we also collected more closely similar or re- lated data from reputable news sites and community sources. When the amount of data has been improved, we summarized Entity Type Train Valid Test NAME AGE GENDER ADDRESS SYM DATE HOS DATE POS DATE ISO DATE 455 472 437 454 358 709 682 698 CON PERSON CON DATE LOCATION 3773 1448 2044 133 138 139 137 49 139 117 140 957 336 1067 146 144 135 137 62 147 140 139 637 262 987 All 734 754 711 728 469 995 939 977 5367 2046 4098 Level 1 entities 10354 2937 2579 15870 Level 2 entities Level 3 entities Level 4 entities 848 282 46 352 301 1501 51 12 42 14 375 72 Entities Sentences 11530 6162 3352 2054 2936 2055 17818 10271 Table 2: Statistics dataset and annotated them, in order to create a NER dataset to train our system’s model and serve for natural language process- ing, artiﬁcial intelligence studies in future. Data was cleaned up by ﬁxing spelling mistakes, typing, removing duplicates, parts unrelated to COVID-19 and obtained 10271 raw sen- tences. We update daily case reports that we can collect, so number of raw sentences will be different from the time we wrote this article. 3.1 Entity Types COVID-19 patient timelines are critical in preventing the spread of epidemic, helping determine how long a patient can infect others (starting from when possibility of infection or symptomatic until quarantine). Based on that, tracing team can ﬁnd patients contact person during that time, test and quarantine infected ones. Realizing the effectiveness of this approach, we deﬁne eleven entity types (described in Table 1) which are important information to support its implemen- tation faster in practice (instead of doing it manually at the moment). These eleven entities were deﬁned after careful consideration in consultation with the medical team: • First, we need to extract patient information including full name (NAME), age (AGE), gender (GENDER) and address (ADDRESS). • Then, we need to extract above important timelines, we have divided date entity into ﬁve different date entities, including symptom onset date (SYM DATE), date of pa- tient contact other (CON DATE), date that patient is ad- mitted to hospital or receives treatment for COVID-19 at another medical facility (e.g. quarantine, ﬁeld hos- pital ...) (HOS DATE), date of initiation of quarantine (ISO DATE) and date conﬁrmed positive for COVID-19 (POS DATE). • Finally, it is necessary to extract names of people who have been in contact with patient and locations where patient has visited during the above time, to isolate and treat people and to localize the area concerned. The challenge with our dataset is that entities are easily confused with each other, for example patient information is confused with that of others, addresses could be confused with other locations, and dates could be confused with each other, so model may misclassify entities. Similar to VLSP 2018 NER, our data has nested entities and only raw text with XML tags in our dataset. Nested entities are also a challenge in our dataset. They are ordered by medical experts, according to their importance in disease prevention (inside entity is more important than outside entity). Ordered entities make experimentation easier and more precise. Statistically, nested entities in our dataset have at most four levels. For instance: Level-1 entities: <ENAMEX TYPE=”ISO DATE”>24/8/2020</ENAMEX> Level-2 entities: <ENAMEX TYPE=“HOS DATE”> <ENAMEX TYPE=“ISO DATE”> 24/8/2020</ENAMEX></ENAMEX> Level-3 entities: <ENAMEX TYPE=“CON DATE”> <ENAMEX TYPE=“HOS DATE”> <ENAMEX TYPE=“ISO DATE”> 24/8/2020</ENAMEX></ENAMEX></ENAMEX> Level-4 entities: <ENAMEX TYPE=“POS DATE”> <ENAMEX TYPE=“CON DATE”> <ENAMEX TYPE=“HOS DATE”> <ENAMEX TYPE=“ISO DATE”> 24/8/2020 </ENAMEX></ENAMEX></ENAMEX></ENAMEX> The importance of each entity is related to medicine ﬁeld so we will not present it details. 3.2 Annotation Our data annotation process is divided into three phases: • First, data from medical facilities including over 1000 patient reports were obtained. Data includes text ﬁles, pdfs and images, which were converted to text then an- notated. Based on VLSP 2018, we manually annotated data with XML tags containing entity types in purpose of research supporting as VLSP 2016 and VLSP 2018. Time to annotate all data in Phase 1, including review is two weeks. At the end of Phase 1, 5154 sentences and 6481 entities have been collected. • Then, we crawled through reputable online news sites containing COVID-19 keyword. These new data con- tains some spelling, formatting errors and some irrel- evant information. We removed duplicates and nor- malized Vietnamese punctuation automatically. After that, unrelated parts were manually removed, typing and spelling errors were manually corrected. We spent two weeks working on it and more than a week later review- ing. After cleaning data, 7952 sentences and 7069 enti- ties have been collected. • In the last phase, we updated more data from commu- nity sources (data processing organizations, public por- tals, etc), normalized and corrected them. This work was completed in two weeks including review. We reviewed all the data once again in two weeks , encrypts personal and sensitive information. After ﬁnishing, we had a total of 10271 sentences and 11128 entities. We divided dataset into three parts: train, validation, and test. Detailed statistics of dataset in Table 2. sentences words and 4 Experiments 4.1 Data processing We segmented and with [Nguyen et al., 2017] Trankit RDRsegmenter [Minh Van Nguyen and Nguyen, 2021] and choose RDRseg- menter for the performance with PhoBERT. Train, validation, and test data were converted into data ﬁles in CoNLL 2003 [Sang and Meulder, 2003] format. For sentence segmen- tation, we found that in many cases, in order to recognize entities, it needs information from several around sentences. In other words, to recognize entity in a certain sentence, we need context of paragraph containing that sentence. For example: Vietnamese: “Ngay 30.8, benh nhan di lam o cong ty den 5h30 chieu. Toi cung ngay, benh nhan duoc xac dinh co tiep xuc voi benh nhan COVID-19 nen duoc dua di cach ly.” English: “On August 30, the patient went to work at the company until 5:30 pm. On the evening of the same day, the patient was identiﬁed as having contact with a COVID-19 patient and was placed in quarantine.” ISO DATE in above sentence is August 30, but to determine it we need to read following sentence: “On the evening of the same day, the patient was identiﬁed as having contact with a COVID-19 patient and was placed in quarantine.” With the ideas of [Luoma and Pyysalo, 2020] about cross- sentence context, each sentence in our dataset is used as the main sentence in each input example. That sentence is placed at the beginning of example and its following sentences (ad- ditional sentences) are ﬁlled in, until the max sequence length is reached. Implement this input construction, our model were trained with broader context that can recognize entities in cases that we mentioned above. We will demonstrate this in experiments. We only consider Level-1 and Level-2 entities because we have statistically found that Level-3 and Level-4 entities are too few to do an assessment. From idea in [Minh, 2018], to handle nested entities, we also combined entity tags of a token into an entity tag, called joint. Example: 02/08/2020 there are 2 entity tags: ISO DATE (level-1) and HOS DATE (level-2), the joint tag is HOS DATE+ISO DATE. We experiment with separate entity levels and joint to compare results between them. 4.2 Training As noted above, entity recognization in our dataset is not an easy task since entities are nested and easy to confuse with each other. So, we used PhoBERT, a pre-trained lan- guage models for Vietnamese which improved the state-of- the-art in multiple Vietnamese-speciﬁc NLP tasks, and NER is one of them. PhoBERT has 2 versions: PhoBERTbase and PhoBERTlarge use two nearly similar architectures (opti- mized based on RoBERTa [Ott et al., 2019]), PhoBERTbase and PhoBERTlarge respectively. PhoBERT is trained on a 20GB word-level Vietnamese dataset, one of the main ideas that makes PhoBERT outperform other models (while oth- ers are trained with syllable-level datasets). We expect that PhoBERT is possible to contextualize words well so that it can reduce confusion between entities and recognize them based on different contexts. Models we used to experiment and evaluated in- clude: BiLSTM-CRF [Huang et al., 2015], PhoBERTbase, PhoBERTlarge, PhoBERTbase-CRF, PhoBERTlarge-CRF. We also used PhoBERTbase-CRF and PhoBERTlarge-CRF with cross-sentence context approach to evaluated its effec- tiveness. We experimented with ﬁne-tuning approach. We used customized Adam [Kingma and Ba, 2015] optimizer of BERT [Devlin et al., 2018] with weight decay of 0.01, learn- ing rate of 5e-5 and batch size of 32, in 100 training epochs, evaluate the task performance after each epoch on the valida- tion set. 4.3 Evaluation We trained models with Level-1 and Level-2 entities sepa- rately, and then combined them to compared with models that were trained with joint-tag entities. We evaluated each model with ﬁve runs based on precision, recall and F1 score to get the most accurate results. 4.4 Results In this subsection we will compare results of models to choose the best model for our system. Recognizing results with Level-1 and Level-2 entities on valid set and test set are presented in Tables 3, 4, 5, 6, respectively. Each model was run ﬁve times, with different random seeds, averaged results presented in tables. It can be seen that approaches based on PhoBERT bring better results than BiLSTM. Based on error analysis, we found that PhoBERTbase and PhoBERTlarge could recognize most of entities, but there were still some en- tities (mostly confusing entities mentioned above) that both models were not recognisable. For example, in some cases, they could not differentiate between ADDRESS and LOCA- TION, NAME and CON PERSON, or dates. That lead to PhoBERTbase and PhoBERTlarge results are not different too much, even in some runs, PhoBERTbase is better, but overall, PhoBERTlarge gives better results. Enhancements (CRF, cross-sentence context) have improved results, espe- cially cross-sentence context. As shown in tables, PhoBERTlarge-CRF with cross- sentence context approach got the best results and we chose it as model for our system. Results of recognizing entities are shown in Table 7. Model recognizes patient’s personal information such as: name, age, gender , address with good results. Model also works well when recognizes patients vis- ited location, people who has been in contact with patient, dates they were in contact, and date when patient has symp- toms. Recognizing ISO DATE, HOS DATE, and POS DATE seem quite difﬁcult. These three days overlap in many cases because case that patient is found positive with COVID-19, then isolated and hospitalized in the same day is popular, but also improved quite well with PhoBERTlarge-CRF with cross-sentence context. 5 Conclusion We presented named entity recognition study on our manu- ally annotated Vietnam COVID-19 dataset which be deﬁned important entity types. We also presented data processing and training on models such as BiLSTM and PhoBERT, with CRF and cross-sentence context approach. We will continue to im- prove our results as best we can and hope that we can deploy them into practice to help the medical team and everyone in prevention pandemic. We also expect that our dataset will drive more future research on COVID-19 prevention, named entity recognition and natural language processing. References [Banda et al., 2020] Juan M. Banda, Ramya Tekumalla, Guanyu Wang, Jingyuan Yu, Tuo Liu, Yuning Ding, Katya Artemova, Elena Tutubalina, and Gerardo Chowell. A large-scale covid-19 twitter chatter dataset for open sci- entiﬁc research – an international collaboration, 2020. [Chen et al., 2020] Q. Chen, A. Allot, and Z. Lu. Keep Nature, up with the latest coronavirus research. 579(7798):193, 2020. [Devlin et al., 2018] Jacob Devlin, Ming-Wei Chang, Ken- ton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understand- ing. arXiv preprint arXiv:1810.04805, 2018. [Hu et al., 2020] Yong Hu, Heyan Huang, Anfan Chen, and Xian-Ling Mao. Weibo-cov: A large-scale covid-19 social media dataset from weibo, 2020. [Huang et al., 2015] Zhiheng Huang, Wei Xu, and Kai Yu. Bidirectional LSTM-CRF models for sequence tagging. CoRR, abs/1508.01991, 2015. [Kieuvongngam et al., 2020] Virapat Kieuvongngam, Bowen Tan, and Yiming Niu. Automatic text summariza- tion of covid-19 medical research articles using bert and gpt-2, 2020. [Kingma and Ba, 2015] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceed- ings of the 3rd International Conference for Learning Rep- resentations, 2015. [Kocaman and Talby, 2020] Veysel Kocaman and David Improving clinical document understanding on Talby. covid-19 research with spark nlp, 2020. [Luoma and Pyysalo, 2020] Jouni Luoma Sampo Pyysalo. Exploring cross-sentence contexts for named In Proceedings of the 28th entity recognition with bert. and International Conference on Computational Linguistics, pages 904–914, 2020. [Minh Van Nguyen and Nguyen, 2021] Amir Trankit: A light-weight Pouran Ben Veyseh Minh Van Nguyen, Viet Lai and Thien Huu transformer-based Nguyen. toolkit for multilingual natural language processing. In the European the 16th Conference of Proceedings of Chapter of the Association for Computational Linguistics: System Demonstrations, 2021. [Nguyen and Nguyen, 2020] Dat Quoc Nguyen [Minh, 2018] Pham Quang Nhat Minh. A feature-based model for nested named-entity recognition at VLSP-2018 NER evaluation campaign. CoRR, abs/1803.08463, 2018. and PhoBERT: Pre-trained language Anh Tuan Nguyen. In Findings of the Association models for Vietnamese. for Computational Linguistics: EMNLP 2020, pages 1037–1042, 2020. [Nguyen and Vu, 2016] Huyen Nguyen and Luong Vu. Vlsp In Pro- 2016 shared task: Named entity recognition. ceedings of Vietnamese Speech and Language Processing (VLSP), 2016. [Nguyen et al., 2017] Dat Quoc Nguyen, Dai Quoc Nguyen, Thanh Vu, Mark Dras, and Mark Johnson. A fast and accu- rate vietnamese word segmenter. CoRR, abs/1709.06307, 2017. [Nguyen et al., 2019] Huyen Nguyen, Quyen Ngo, Luong Vu, Vu Tran, and Hien Nguyen. Vlsp shared task: Named entity recognition. Journal of Computer Science and Cy- bernetics, 34(4):283–294, 2019. [Ott et al., 2019] Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for se- quence modeling. In Proceedings of NAACL-HLT 2019: Demonstrations, 2019. [Sang and Meulder, 2003] Erik F. Tjong Kim Sang and Fien De Meulder. Introduction to the conll-2003 shared task: Language-independent named entity recognition. CoRR, cs.CL/0306050, 2003. [Truong et al., 2021] Thinh Hung Truong, Mai Hoang Dao, and Dat Quoc Nguyen. COVID-19 Named Entity Recog- nition for Vietnamese. In Proceedings of the 2021 Confer- ence of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo- gies, 2021. [Wang et al., 2020] Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Doug Bur- dick, Darrin Eide, Kathryn Funk, Yannis Katsis, Rodney Kinney, Yunyao Li, Ziyang Liu, William Merrill, Paul Mooney, Dewey Murdick, Devvret Rishi, Jerry Sheehan, Zhihong Shen, Brandon Stilson, Alex Wade, Kuansan Wang, Nancy Xin Ru Wang, Chris Wilhelm, Boya Xie, Douglas Raymond, Daniel S. Weld, Oren Etzioni, and Se- bastian Kohlmeier. Cord-19: The covid-19 open research dataset, 2020. [Zong et al., 2020] Shi Zong, Ashutosh Baheti, Wei Xu, and Alan Ritter. Extracting covid-19 events from twitter, 2020. Models Level-1 Joint Prec. Recall F1 Prec. Recall F1 Bi-LSTM-CRF 66.06 75.31 70.38 65.21 68.51 66.82 PhoBERTbase PhoBERTlarge 81.31 83.54 82.41 74.37 77.95 76.12 81.52 83.65 82.57 74.35 78.25 76.25 PhoBERTbase-CRF 82.42 83.12 82.77 74.93 79.32 77.06 PhoBERTlarge-CRF 82.02 83.78 82.89 75.17 79.79 77.41 PhoBERTbase-CRF 82.83 84.51 83.66 76.60 80.71 78.60 +cross-sentence context PhoBERTlarge-CRF 82.25 85.78 83.98 76.29 81.12 78.63 +cross-sentence context Table 3: Results (measured with Precision, Recall and F1-score) on valid set, recognizing Level-1 entities with models Models Level-2 Joint Prec. Recall F1 Prec. Recall F1 Bi-LSTM-CRF 60.64 64.12 62.33 61.59 66.13 63.78 PhoBERTbase PhoBERTlarge 68.56 72.15 70.31 67.44 70.55 68.96 69.35 72.65 70.96 68.58 72.62 70.54 PhoBERTbase-CRF 68.88 72.79 70.78 68.24 72.38 70.25 PhoBERTlarge-CRF 69.73 73.22 71.43 68.09 72.66 70.30 PhoBERTbase-CRF 72.62 74.14 73.37 69.23 73.39 71.25 +cross-sentence context PhoBERTlarge-CRF 73.04 74.23 73.63 68.90 73.85 71.29 +cross-sentence context Table 4: Results (measured with Precision, Recall and F1-score) on valid set, recognizing Level-2 entities with models Models Level-1 Joint Prec. Recall F1 Prec. Recall F1 Bi-LSTM-CRF 69.46 71.12 70.28 68.60 71.31 69.93 PhoBERTbase PhoBERTlarge 78.95 81.59 80.25 72.65 74.12 73.38 78.69 82.17 80.39 72.25 74.15 73.19 PhoBERTbase-CRF 80.02 81.88 80.94 72.91 75.31 74.09 PhoBERTlarge-CRF 80.09 82.65 81.35 73.64 75.69 74.65 PhoBERTbase-CRF 80.68 83.14 81.89 74.99 77.22 76.09 +cross-sentence context PhoBERTlarge-CRF 81.08 83.63 82.34 74.31 78.13 76.17 +cross-sentence context Table 5: Results (measured with Precision, Recall and F1-score) on test set, recognizing Level-1 entities with models Models Level-2 Joint Prec. Recall F1 Prec. Recall F1 Bi-LSTM-CRF 54.16 54.44 54.30 51.49 54.12 52.77 PhoBERTbase PhoBERTlarge 63.06 65.51 64.26 57.81 62.12 59.89 63.46 65.74 64.58 57.80 61.79 59.73 PhoBERTbase-CRF 64.99 65.03 65.01 58.02 62.36 60.11 PhoBERTlarge-CRF 63.41 67.24 65.27 56.82 62.78 59.65 PhoBERTbase-CRF 64.87 69.23 66.98 58.31 63.53 60.81 +cross-sentence context PhoBERTlarge-CRF 65.09 69.51 67.23 58.03 63.23 60.52 +cross-sentence context Table 6: Results (measured with Precision, Recall and F1-score) on test set, recognizing Level-2 entities with models Dataset Measure NAM. AGE GEN. ADD. SYM. POS. HOS. ISO. LOC. C.DATE C.PER. Prec. 99.08 97.69 98.31 99.87 83.29 71.17 76.79 74.78 77.97 86.02 85.67 Valid Recall 99.93 99.38 99.99 98.46 87.25 74.21 78.59 78.18 82.39 87.59 86.19 F1 99.50 98.53 99.15 99.16 85.23 72.66 77.68 76.44 80.12 86.80 85.93 Prec. 95.18 98.47 99.89 98.62 74.29 74.54 75.85 78.54 79.20 85.45 84.83 Test Recall 96.12 99.31 99.65 98.72 75.42 77.89 79.12 81.20 83.60 87.19 88.24 F1 95.65 98.89 99.77 98.67 74.85 76.18 77.45 79.85 81.34 86.31 86.50 Table 7: Results (measured with Precision, Recall and F1-score) on valid, test set entities, recognizing with PhoBERTlarge-CRF with cross- sentence context approach